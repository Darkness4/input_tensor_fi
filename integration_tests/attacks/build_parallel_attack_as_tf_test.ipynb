{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advance-saturday",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "original-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = os.getcwd()\n",
    "MODEL_PATH = os.path.join(FILE_PATH, \"../models/my_vgg.h5\")\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-madagascar",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accepting-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def __prepare_datasets():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return (x_train, y_train), (x_test[:20], y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-integration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (50000, 32, 32, 3) y_train.shape = (50000, 10)\n",
      "x_test.shape = (20, 32, 32, 3) y_test.shape = (20, 10)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = __prepare_datasets()\n",
    "x_train, y_train = data_train\n",
    "x_test, y_test = data_test\n",
    "print(f\"x_train.shape = {x_train.shape} y_train.shape = {y_train.shape}\")\n",
    "print(f\"x_test.shape = {x_test.shape} y_test.shape = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-activation",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "floppy-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integration_tests.models.my_vgg import my_vgg\n",
    "\n",
    "def __prepare_model(data_train, data_test):\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(\"---Using Existing Model---\")\n",
    "        model: tf.keras.Model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    else:\n",
    "        print(\"---Training Model---\")\n",
    "        print(f\"GPU IS AVAILABLE: {tf.config.list_physical_devices('GPU')}\")\n",
    "        model: tf.keras.Model = my_vgg()\n",
    "        model.fit(\n",
    "            *data_train,\n",
    "            epochs=100,\n",
    "            batch_size=64,\n",
    "            validation_data=data_test,\n",
    "        )\n",
    "        model.save(MODEL_PATH)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "substantial-magnitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Using Existing Model---\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 698,154\n",
      "Trainable params: 698,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = __prepare_model(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-enlargement",
   "metadata": {},
   "source": [
    "# Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deluxe-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_perturb_image(xs, img):\n",
    "    # If this function is passed just one perturbation vector,\n",
    "    # pack it in a list to keep the computation the same\n",
    "    if xs.ndim < 2:\n",
    "        xs = np.array([xs])\n",
    "\n",
    "    # Copy the image n == len(xs) times so that we can\n",
    "    # create n new perturbed images\n",
    "    tile = [len(xs)] + [1] * (xs.ndim + 1)\n",
    "    imgs = np.tile(img, tile)\n",
    "\n",
    "    # Make sure to floor the members of xs as int types\n",
    "    xs = xs.astype(int)\n",
    "\n",
    "    for x, img in zip(xs, imgs):\n",
    "        # Split x into an array of 5-tuples (perturbation pixels)\n",
    "        # i.e., [[x,y,r,g,b], ...]\n",
    "        pixels = np.split(x, len(x) // 5)\n",
    "        for pixel in pixels:\n",
    "            # At each pixel's x,y position, assign its rgb value\n",
    "            x_pos, y_pos, *rgb = pixel\n",
    "            img[x_pos, y_pos] = rgb\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greater-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(\n",
    "    xs: np.ndarray, img: np.ndarray, y_true: int, model: tf.keras.Model\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Perturb the image and get the predictions of the model.\"\"\"\n",
    "    imgs_perturbed = original_perturb_image(xs, img)\n",
    "    predictions = model.predict(imgs_perturbed)[:, y_true]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "involved-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "def attack_success(\n",
    "    x: np.ndarray, img: np.ndarray, y_true: int, model: tf.keras.Model\n",
    ") -> Optional[bool]:\n",
    "    \"\"\"Predict ONE image and return True if expected. None otherwise.\"\"\"\n",
    "    attack_image = original_perturb_image(x, img)\n",
    "\n",
    "    confidence = model.predict(attack_image)[0]\n",
    "    predicted_class = np.argmax(confidence)\n",
    "\n",
    "    # If the prediction is what we want (misclassification or\n",
    "    # targeted classification), return True\n",
    "    logging.debug(f\"Confidence: {confidence[y_true]}\")\n",
    "    if predicted_class == y_true:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exposed-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from inputtensorfi.attacks.differential_evolution import differential_evolution\n",
    "\n",
    "def build_attack(\n",
    "    model: tf.keras.Model,\n",
    "    pixel_count=1,\n",
    "    maxiter=75,\n",
    "    popsize=400,\n",
    "    verbose=False,\n",
    "):\n",
    "    def attack(\n",
    "        img: np.ndarray,\n",
    "        y_true: int,\n",
    "    ):\n",
    "        # Define bounds for a flat vector of x,y,r,g,b values\n",
    "        # For more pixels, repeat this layout\n",
    "        bounds = [(0, 32), (0, 32), (0, 256), (0, 256), (0, 256)] * pixel_count\n",
    "\n",
    "        # Population multiplier, in terms of the size of the perturbation vector x\n",
    "        popmul = max(1, popsize // len(bounds))\n",
    "\n",
    "        # Format the predict/callback functions for the differential evolution algorithm\n",
    "        def predict_fn(xs):\n",
    "            return predict_classes(xs, img, y_true, model)\n",
    "\n",
    "        def callback_fn(x, convergence):\n",
    "            return attack_success(\n",
    "                x,\n",
    "                img,\n",
    "                y_true,\n",
    "                model,\n",
    "            )\n",
    "\n",
    "        # Call Scipy's Implementation of Differential Evolution\n",
    "        attack_result = differential_evolution(\n",
    "            predict_fn,\n",
    "            bounds,\n",
    "            maxiter=maxiter,\n",
    "            popsize=popmul,\n",
    "            recombination=1,\n",
    "            atol=-1,\n",
    "            callback=callback_fn,\n",
    "            polish=False,\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            # Calculate some useful statistics to return from this function\n",
    "            attack_image = original_perturb_image(attack_result.x, img)[0]\n",
    "            prior_probs = model.predict(np.array([img]))[0]\n",
    "            prior_class = np.argmax(prior_probs)\n",
    "            predicted_probs = model.predict(np.array([attack_image]))[0]\n",
    "            predicted_class = np.argmax(predicted_probs)\n",
    "            success = predicted_class != y_true\n",
    "            cdiff = prior_probs[y_true] - predicted_probs[y_true]\n",
    "\n",
    "            print(\n",
    "                dedent(\n",
    "                    \"-- TRUTH --\\n\"\n",
    "                    f\"y_true={y_true}\\n\"\n",
    "                    \"-- W/O FI PREDS --\\n\"\n",
    "                    f\"prior_probs={prior_probs}\\n\"\n",
    "                    f\"prior_class={prior_class}\\n\"\n",
    "                    \"-- FI PREDS --\\n\"\n",
    "                    f\"attack_results={attack_result.x}\\n\"\n",
    "                    f\"predicted_probs={predicted_probs}\\n\"\n",
    "                    f\"predicted_class={predicted_class}\\n\"\n",
    "                    f\"success={success}\\n\"\n",
    "                    f\"cdiff={cdiff}\\n\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return attack_result.x\n",
    "\n",
    "    return attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-criticism",
   "metadata": {},
   "source": [
    "Convert the fault injector based on numpy to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "completed-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attack_as_tf(\n",
    "    model: tf.keras.Model,\n",
    "    pixel_count=1,\n",
    "    maxiter=75,\n",
    "    popsize=400,\n",
    "    verbose=False,\n",
    "):\n",
    "    attack = build_attack(\n",
    "        model,\n",
    "        pixel_count=pixel_count,\n",
    "        maxiter=maxiter,\n",
    "        popsize=popsize,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    def attack_as_tf(img, y_true):\n",
    "        return tf.numpy_function(attack, [img, y_true], tf.double)\n",
    "\n",
    "    return attack_as_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-father",
   "metadata": {},
   "source": [
    "Create a new tensor to perform the parallel calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parallel_attack_as_tf(\n",
    "    model,\n",
    "    pixel_count=1,\n",
    "    maxiter=75,\n",
    "    popsize=400,\n",
    "    verbose=False,\n",
    "):\n",
    "    @tf.function\n",
    "    def parallel_attack_as_tf(\n",
    "        imgs,\n",
    "        y_trues,\n",
    "    ):\n",
    "        attack_as_tf = build_attack_as_tf(\n",
    "            model,\n",
    "            pixel_count=pixel_count,\n",
    "            maxiter=maxiter,\n",
    "            popsize=popsize,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        return tf.vectorized_map(\n",
    "            lambda x: attack_as_tf(x[0], x[1]), elems=[imgs, y_trues]\n",
    "        )\n",
    "\n",
    "    return parallel_attack_as_tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-shadow",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-attitude",
   "metadata": {},
   "source": [
    "Avoid working in categorical (binary matrix classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "insured-imagination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([np.argmax(y) for y in y_test])\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "agreed-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting PyFunc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.33434186e+01, 2.18139778e+01, 2.95123994e+01, 4.75965967e+01,\n",
       "        5.92697516e+01],\n",
       "       [2.65945576e+01, 8.64797740e+00, 2.22553328e+02, 2.05020628e+02,\n",
       "        1.72759285e+02],\n",
       "       [2.39763153e+01, 2.33670395e+01, 2.55391322e+02, 2.55775207e+02,\n",
       "        2.15465893e+02],\n",
       "       [2.27173569e+01, 4.28794542e+00, 6.63671927e-02, 4.82242720e-01,\n",
       "        2.07104240e-01],\n",
       "       [1.52169177e+01, 2.36333808e+01, 1.89231426e+01, 2.00517746e+01,\n",
       "        2.14268126e+01],\n",
       "       [2.40617401e+01, 2.01067137e+01, 2.21243086e+02, 1.60033769e+02,\n",
       "        2.33612946e+02],\n",
       "       [2.96925734e+01, 1.16100369e+01, 2.54726614e+02, 2.55755097e+02,\n",
       "        2.55202340e+02],\n",
       "       [1.44771991e+01, 1.57277695e+01, 2.55752698e+02, 2.40635936e+02,\n",
       "        1.83080361e+02],\n",
       "       [8.82964159e+00, 1.04277558e+01, 2.70171034e+01, 4.24620191e-01,\n",
       "        2.18372455e-01],\n",
       "       [1.90627662e+00, 1.87983121e+01, 2.31881191e+01, 7.06750622e+01,\n",
       "        5.76902802e+01],\n",
       "       [2.63527472e+01, 2.52167631e+01, 1.03404656e+01, 1.32476053e+02,\n",
       "        1.10857345e+02],\n",
       "       [1.41325979e+01, 5.52546308e+00, 7.45930259e+01, 7.31086319e+00,\n",
       "        5.99761076e+00],\n",
       "       [2.88877513e+01, 2.30655270e+01, 2.42954445e+02, 2.04504664e+02,\n",
       "        2.15437192e+02],\n",
       "       [1.02249125e+01, 2.27707156e+01, 1.78269601e+00, 8.40507560e+01,\n",
       "        2.46610619e+00],\n",
       "       [2.97846960e+01, 2.91192712e+01, 2.19668414e+02, 2.17712987e+02,\n",
       "        2.55355438e+02],\n",
       "       [2.65506545e+01, 9.62436075e+00, 2.55227324e+02, 2.55353775e+02,\n",
       "        2.55714105e+02],\n",
       "       [3.72619658e+00, 2.55034294e+01, 2.47759436e+02, 1.06453117e+01,\n",
       "        1.20147308e+02],\n",
       "       [1.98200145e+01, 1.75431769e+01, 1.31161446e+02, 1.47698270e+02,\n",
       "        2.41507045e+02],\n",
       "       [2.17285577e+01, 1.74366290e+01, 2.28629315e+02, 2.45987575e+02,\n",
       "        2.31495769e+02],\n",
       "       [1.45053697e+01, 1.12223707e+01, 9.56496215e-01, 2.73144964e+01,\n",
       "        7.47469547e+01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_parallel_attack_as_tf(model)(x_test, y_true).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-oracle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
